{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from keras.models import Sequential\nimport keras.layers\nimport keras.utils\nfrom keras.layers import Conv2D, Activation\nfrom keras.layers import MaxPool2D\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg16 import VGG16\nfrom keras.layers.core import Activation\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt","metadata":{"id":"ie4bPHYindIZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/drive')","metadata":{"id":"5MY7mOMEpUOz","outputId":"e3aef7c0-a35f-474b-c35a-18d7607cd25e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folder_path_train =\"/content/drive/MyDrive/HMD_project/train.jsonl\"\nfolder_path_dev =\"/content/drive/MyDrive/HMD_project/dev.jsonl\"\ntrain = pd.read_json(folder_path_train,lines=True)\n\n\nval=pd.read_json(folder_path_dev,lines=True)\n\nprint(train.head(1))\nprint(train.label.value_counts())","metadata":{"id":"QjGS9u0hpyBC","outputId":"ed7f1f5b-c834-4b9a-fb44-8e8213377c3b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read train and validation dataset information from json file","metadata":{"id":"Fee7FNAWndIn"}},{"cell_type":"code","source":"# for local machine\n# train=pd.read_json('/media/adb/Data/Sabudh_training_DS10/Hateful_meme_Sangita/HMD_code/train.jsonl',lines=True)\n# val=pd.read_json('/media/adb/Data/Sabudh_training_DS10/Hateful_meme_Sangita/HMD_code/dev.jsonl',lines=True)\n","metadata":{"id":"ERrOzzTandIs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load image from training dataset\n# N.B: All images are resized (224x224x3) using PIL and saved in drive due to limitations in space","metadata":{"id":"pnc6qcsundIu"}},{"cell_type":"code","source":"\nimg_path=train.img\nimg_label=train.label\nl=len(img_path)\n\nx=[]\ny=[]\n\nfor i in range(l):\n    print(i)\n  \n    img_=Image.open(\"/content/drive/MyDrive/HMD_project/\"+str(img_path[i])+\".png\")\n    img_files=np.array(img_)\n    # img_files=(img_files/255.0).astype(np.float16)\n  \n    \n    if img_files.shape==(224,224,4):\n        img_files=img_files[:,:,0:3]\n        \n    x.append(img_files)\n    y.append(img_label[i])\nx_arr=np.array(x)\nx_arr.shape\n","metadata":{"id":"BqxlnGyWndIw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load images from validation dataset","metadata":{"id":"WaoWJ1MlyGd9"}},{"cell_type":"code","source":"img_path=val.img\nimg_label=val.label\nl=len(img_path)\n\nx_val=[]\ny_val=[]\n\nfor i in range(l):\n  \n    img_=Image.open(\"/content/drive/MyDrive/HMD_project/\"+str(img_path[i])+\".png\")\n    img_files=np.array(img_)\n    # img_files=(img_files/255.0).astype(np.float16)\n    \n\n    if img_files.shape==(224,224,4):\n        img_files=img_files[:,:,0:3]\n        \n    x_val.append(img_files)\n    y_val.append(img_label[i])\nx_val=np.array(x_val)\ny_val=np.array(y_val)\nx_val.shape","metadata":{"id":"RL4gE8lWyFns","outputId":"ac224c07-7771-4a57-d165-190875d3c802"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# for data balancing in training dataset create augmented images from hate images and save the images in a folder","metadata":{"id":"qTK4d-3wndI0"}},{"cell_type":"code","source":"\nlst=train['label']==1  # hate images\nlist_1=train[lst]\n\nprint(\"Total no. of hate images in training dataset\",list_1.label.value_counts())\nid_1=np.random.randint(0,len(list_1),size=1200) # create id for 1200 random images\n\nlen(id_1)","metadata":{"id":"gqXU1v5FndI1","outputId":"cbfe2b10-7faa-4735-da88-a646f65a3506"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nl=len(id_1)\nid_lst=[]\naug_text=[]\n\nfor i in range(l):\n    img=Image.open('/content/drive/MyDrive/HMD_project/'+str(list_1.iloc[id_1[i]].img)+\".png\")\n    id=list_1.iloc[id_1[i]].id\n\n    id_img=\"augmented/Aug_\"+str(id)+\".png\"\n    id_lst.append(id_img)   # save path of augmented images to a list for further loading\n\n    new_text=list_1.iloc[id_1[i]].text # make a list of text for corresponding images\n    aug_text.append(new_text)\n\n   \n    con=np.random.randint(0,2)\n\n    if con==0:\n        data_aug= keras.layers.RandomFlip(mode=\"horizontal\")\n        a=data_aug(img)\n    else:\n        data_aug= keras.layers.RandomRotation(factor=(0.02,0.1))\n        a=data_aug(img)\n\n    pil_img = keras.utils.array_to_img(a)\n    \n    # save the augmented images in a folder named Augmented_label1\n    pil_img.save('/content/drive/MyDrive/HMD_project/augmented/Aug_'+str(id)+'.png')\n","metadata":{"id":"pjyR1vepndI3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save the list of text in a txt file for text processing\nfile=open('/content/drive/MyDrive/HMD_project/text_aug_norm.txt','w')\nfor i in aug_text:\n    file.write(i+'\\n')\n","metadata":{"id":"D7S2sxTevSVc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# read the augmeted images from the folder using list of paths","metadata":{"id":"E4M92JI7ndI5"}},{"cell_type":"code","source":"x_train_aug=[]\nl=len(id_lst)\n\nfor i in range(l):\n    img_aug=Image.open('/content/drive/MyDrive/HMD_project/'+str(id_lst[i]))\n    \n    imp_file=np.array(img_aug)\n    # imp_file=(imp_file/255.0).astype(np.float16)\n  \n    x_train_aug.append(imp_file)\n\ny_train_aug=np.ones(len(x_train_aug))\n\nprint('Data samples in Augmented dataset:',len(x_train_aug))","metadata":{"id":"vvgXshIGndI6","outputId":"b6201ed6-5943-40de-f8f3-1d2e7c32501c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print((x[0].dtype))\nprint(x_train_aug[0].dtype)","metadata":{"id":"SgUg4ehPT6dn","outputId":"fa6a2a4e-b30d-4596-e465-906045cb8277"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.extend(x_train_aug)\ny.extend(y_train_aug)","metadata":{"id":"KEH114wLndI8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train=np.array(x)\ny_train=np.array(y)\n\nprint(x_train.shape)\nprint(y_train.shape)","metadata":{"id":"5Xct0LttndI9","outputId":"2fd8f530-df4c-49c0-d946-f34be5deeaa6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# VGG16 without top layer","metadata":{"id":"v31h2qEbzKjJ"}},{"cell_type":"code","source":"model_input=x_train\nmodel_input_val=x_val","metadata":{"id":"BGxnlpuEzT6t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn=Sequential()\n#1\ncnn.add(Conv2D(input_shape=(224,224,3),data_format='channels_last',filters=64,padding='same',kernel_size=(3,3),activation='relu'))\ncnn.add(Conv2D(filters=64,padding='same',kernel_size=(3,3),activation='relu'))\ncnn.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n#2\ncnn.add(Conv2D(filters=128,padding='same',kernel_size=(3,3),activation='relu'))\ncnn.add(Conv2D(filters=128,padding='same',kernel_size=(3,3),activation='relu'))\ncnn.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n#3\ncnn.add(Conv2D(filters=256,padding='same',kernel_size=(3,3),activation='relu'))\ncnn.add(Conv2D(filters=256,padding='same',kernel_size=(3,3),activation='relu'))\ncnn.add(Conv2D(filters=256,padding='same',kernel_size=(3,3),activation='relu'))\ncnn.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n#4\ncnn.add(Conv2D(filters=512,padding='same',kernel_size=(3,3),activation='relu'))\ncnn.add(Conv2D(filters=512,padding='same',kernel_size=(3,3),activation='relu'))\ncnn.add(Conv2D(filters=512,padding='same',kernel_size=(3,3),activation='relu'))\ncnn.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n#5\ncnn.add(Conv2D(filters=512,padding='same',kernel_size=(3,3),activation='relu'))\ncnn.add(Conv2D(filters=512,padding='same',kernel_size=(3,3),activation='relu'))\ncnn.add(Conv2D(filters=512,padding='same',kernel_size=(3,3),activation='relu'))\ncnn.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n\n\n# weights from VGG16 model\nvggmodel=(VGG16(include_top=False, weights='imagenet'))\nvggmodel.save('/content/drive/MyDrive/HMD_project/trained_model.h5')\ncnn.load_weights('/content/drive/MyDrive/HMD_project/trained_model.h5')\n\nfor layer in cnn.layers:\n    layer.trainable=False\n\ncnn.add(Flatten())","metadata":{"id":"dR7VWxLizES-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# save cnn outputs for both train and test dataset","metadata":{"id":"wdP5JNOLzzuN"}},{"cell_type":"code","source":"\noutput=cnn.predict(model_input,batch_size=50)\noutput.shape\n# f=open('/content/drive/MyDrive/HMD_project/cnn_train_op.npy', 'wb')\nnp.save('/content/drive/MyDrive/HMD_project/cnn_train_op_norm.npy',output)\n\n\n","metadata":{"id":"1s70WgXfndJB","outputId":"2a653575-4d2b-4631-e7aa-4157022bab2e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\noutput_val=cnn.predict(model_input_val,batch_size=50)\nprint(output_val.shape)\n# f=open('/content/drive/MyDrive/HMD_project/cnn_val_op.npy', 'wb')\nnp.save('/content/drive/MyDrive/HMD_project/cnn_val_op_norm.npy',output_val)\n","metadata":{"id":"popugGU1zDoW","outputId":"b6bdf7bb-f6e6-4982-af87-cd1958631f6b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Autoencoder","metadata":{"id":"lfEQmIn00xY4"}},{"cell_type":"markdown","source":"# Data normalization ","metadata":{"id":"ZXzB_I-v036c"}},{"cell_type":"code","source":"model_input=output   # CNN output\nmodel_input_norm=model_input/np.max(model_input)\nmodel_input=model_input_norm.astype(np.float16)","metadata":{"id":"7mGbMtLC0TnX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# design the encoder and decoder segments by selecting the hyper-parameters","metadata":{"id":"_Pu4PJB14Rwq"}},{"cell_type":"code","source":"model=Sequential()\nfrom keras.layers import BatchNormalization\n\nfrom keras.layers import Dropout\n\n# model.add(keras.Input(shape=(output.shape[-1],)))\n\nmodel.add(Dense(500,input_shape=(model_input.shape[-1],),activation='relu',name=\"encoder1\"))\nmodel.add(Dropout(0.25))\n# model.add(BatchNormalization())\nmodel.add(Dense(200,activation='relu',name=\"encoder2\"))\nmodel.add(Dropout(0.1))\n\nmodel.add(Dense(200,activation='relu',name=\"encoder3\"))\n# model.add(BatchNormalization())\n# model.add(Dropout(0.1))\nmodel.add(Dense(200,activation='relu',name=\"decoder1\"))\nmodel.add(Dropout(0.1))\n# model.add(BatchNormalization())\nmodel.add(Dense(500,activation='relu',name=\"decoder2\"))\n# model.add(BatchNormalization())\n\nmodel.add(Dropout(0.25))\nmodel.add(Dense(model_input.shape[-1],activation='relu',name=\"decoder3\"))\n\n\nmodel.summary()","metadata":{"id":"Qe7YQqm3ndJD","outputId":"6c97433e-f08a-4bc8-bf42-33c6f0656523"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel.compile(loss='mse',optimizer='adam')\nhistory=model.fit(model_input,model_input,epochs=200,batch_size=128,shuffle=True,validation_split=0.2)\nprint(history.history.keys())","metadata":{"id":"DisNazPOndJE","outputId":"43c67b05-c7d2-4eb3-96d2-b9c79e02ad80"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"3dSL1ufp2MTd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\nplt.plot(history.history['loss'],label='train_loss')\nplt.plot(history.history['val_loss'],label='val_loss')\nplt.legend()\nplt.show()\n","metadata":{"id":"l-fYM9fu8P6U","outputId":"9f448e8d-1dce-4866-c2d0-2ddc125470b3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# save image embedding (taken from encoder output) and label in a numpy file","metadata":{"id":"7_GIrbP23xcj"}},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras import backend as K\n\nlayer_ID = 4\nget_output = K.function([model.get_layer(index=0).input], model.get_layer(index=layer_ID).output)\n\nembedded_train_img = get_output([model_input])  # input_data is a numpy array\nprint((embedded_train_img).shape)\n\ntrain_img=np.append(embedded_train_img,y_train,axis=1)\n\nnp.save('/content/drive/MyDrive/HMD_project/HMD_classifier/embedding_train_img_norm.npy',train_img)\nprint(train_img.shape)\n\n","metadata":{"id":"x18Ls0bH2pao","outputId":"000a2422-12b9-4159-a1e2-3ec220d30c3a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_input_val_norm=output_val/np.max(output_val)\n\nmodel_input_val=model_input_val_norm.astype(np.float16)\nmodel_input_val.shape","metadata":{"id":"-3MQQF8WcZ-H","outputId":"b7c55b96-5e4e-4595-b1c4-14b31ac18a2b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_val=y_val.reshape(y_val.size,1)\n\nembedded_val_img = get_output([model_input_val])  # input_data is a numpy array\nprint((embedded_val_img).shape)\n\nval_img=np.append(embedded_val_img,y_val,axis=1)\nnp.save('/content/drive/MyDrive/HMD_project/HMD_classifier/embedding_val_img_norm.npy', val_img)\nprint(val_img.shape)\n","metadata":{"id":"E59ssRXZ15xL","outputId":"a6860372-7344-4643-d751-780c39737cba"},"execution_count":null,"outputs":[]}]}